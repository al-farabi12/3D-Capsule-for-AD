{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raid/anagashbayev/3D-Capsule-for-AD/\n",
      "/raid/anagashbayev/\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nb\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam,SGD\n",
    "from torchvision import datasets, transforms\n",
    "import datetime\n",
    "USE_CUDA = True\n",
    "random_seed= 42\n",
    "random.seed( random_seed )\n",
    "root = os.getcwd()+'/'\n",
    "print(root)\n",
    "currentFolder = \"3D-Capsule-for-AD/\"\n",
    "data_path=root[:-len(currentFolder)]\n",
    "print(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Patients 462\n",
      "Number of images in each group {'AD': 193, 'MCI': 909, 'CN': 442}\n"
     ]
    }
   ],
   "source": [
    "data_15t_1mm = data_path+'15t/1mm-reg-nii-gz/'\n",
    "data_15t_2mm = data_path+'15t/2mm-reg-nii-gz/'\n",
    "data_3t_1mm = data_path+'3t/1mm-reg-nii-gz/'\n",
    "data_3t_2mm = data_path+'3t/2mm-reg-nii-gz/'\n",
    "data_type = [data_15t_1mm, data_15t_2mm, data_3t_1mm, data_3t_2mm]\n",
    "choice = 1 # 0==( 15t 1mm ) 1==(15t 2mm ) 2==( 3t 1mm ) 3==( 3t 2mm ) \n",
    "diagnos = {'AD': 0,'MCI': 1,'CN': 2}\n",
    "val_dia = { 0:'AD', 1:'MCI',2:'CN'}\n",
    "# diagnos = {'AD': 0,'CN': 1}\n",
    "# val_dia = { 0:'AD', 1:'CN'}\n",
    "batch_size = 2#SHOULD BE devisable by 3\n",
    "\n",
    "\n",
    "\n",
    "n_classes_by_val= len(set(diagnos.values()))\n",
    "n_classes= len(set(diagnos))\n",
    "all_data = os.listdir(data_type[choice])\n",
    "all_subjects = set([i[:10] for i in all_data])\n",
    "print(f\"Total Number of Patients {len(all_subjects)}\")\n",
    "# grouped_data = [[pat for pat in all_data if cls in pat] for cls in diagnos]\n",
    "grouped_data_imgs = {cls:[pat for pat in all_data if cls in pat] for cls in diagnos}\n",
    "print(\"Number of images in each group\", {k:len(v) for k,v in grouped_data_imgs.items()})\n",
    "# grouped_data_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects in each group {'AD': 89, 'MCI': 212, 'CN': 161}\n"
     ]
    }
   ],
   "source": [
    "grouped_data_sub = {k:list(set([img[:10] for img in v])) for k,v in grouped_data_imgs.items()}\n",
    "# grouped_data_sub\n",
    "print(\"Number of subjects in each group\", {k:len(v) for k,v in grouped_data_sub.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_number = False\n",
    "if by_number:\n",
    "    test_sub_per_class = 19 \n",
    "    test_sub = [random.sample(v,test_sub_per_class) for k,v in grouped_data_sub.items()]\n",
    "else:\n",
    "    validation_split = .2\n",
    "    test_sub = [random.sample(v,int(validation_split*len(v))) for k,v in grouped_data_sub.items()]\n",
    "# test_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pat = []\n",
    "for i in range(n_classes):\n",
    "    train_pat.append([])\n",
    "for idx,i in enumerate(grouped_data_pat):\n",
    "    for idx2,ii in enumerate(i):\n",
    "        if ii not in test_pat[idx]:\n",
    "            (train_pat[idx]).append(ii)\n",
    "        if len(train_pat[idx])==70:\n",
    "            break\n",
    "# for i in train_pat:\n",
    "#     print(len(i))\n",
    "by_diag = {}\n",
    "for i in diagnos:\n",
    "    by_diag[i]={}\n",
    "for pat in all_data:\n",
    "    name, image, diagnose =pat.split(\"__\")\n",
    "    if diagnose in diagnos:\n",
    "        if name not in by_diag[diagnose]:\n",
    "            by_diag[diagnose][name]={}\n",
    "        by_diag[diagnose][name][image]=pat\n",
    "n_subj_test = [len(i) for i in test_pat]\n",
    "# n_subj_train  = [len(grouped_data_pat[idx])-n_subj_test[idx] for idx,i in enumerate(by_diag) if i in diagnos]\n",
    "n_subj_train  = [len(i) for i in train_pat]\n",
    "n_subj_total = [n_subj_train[i]+n_subj_test[i] for i in range(n_classes)]\n",
    "# n_subj_test,n_subj_train,n_subj_total\n",
    "test_list_images_by_dia = [[ii for ii in i if ii[:10] in test_pat[idx] ] for idx,i in enumerate(grouped_data)]\n",
    "test_tot =0\n",
    "for i in test_list_images_by_dia:\n",
    "    test_tot += len(i)\n",
    "print('Total test images ',test_tot)\n",
    "train_list_images_by_dia = [[ii for ii in i if ii[:10] in train_pat[idx]] for idx,i in enumerate(grouped_data)]\n",
    "train_tot = 0\n",
    "for i in train_list_images_by_dia:\n",
    "    train_tot += len(i)\n",
    "print('Total train images ',train_tot)\n",
    "all_img = []\n",
    "for i in test_list_images_by_dia:\n",
    "    all_img = all_img+i\n",
    "for i in train_list_images_by_dia:\n",
    "    all_img = all_img+i\n",
    "class MyData3(Dataset):\n",
    "    def __init__(self, path,all_imgs):\n",
    "        self.folder=path\n",
    "        self.img = all_imgs\n",
    "        self.len = len(self.img)\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def __getitem__(self, index):\n",
    "#         temp_size=100\n",
    "#         vol = torch.zeros(temp_size,temp_size,temp_size,dtype=torch.float32)\n",
    "        add_noise = False #random.sample([True,False],1)[0]\n",
    "        di = self.img[index].split('__')[-1]\n",
    "        name =  os.path.join(self.folder,self.img[index])+'/mri/registered.nii.gz'\n",
    "        nii = nb.load(name)\n",
    "        volume = torch.from_numpy(nii.get_fdata()).type(torch.FloatTensor)#[7:82,10:100,10:75]\n",
    "#         x,y,z = volume.shape\n",
    "#         if add_noise:\n",
    "#             noise = 10*torch.randn(volume.shape)\n",
    "#             volume = volume + noise\n",
    "#         x,y,z= random.randint(0,temp_size-x),random.randint(0,temp_size-y),random.randint(0,temp_size-z)\n",
    "\n",
    "        volume = volume/volume.max()\n",
    "#         vol[x:x+75,y:y+90,z:z+65]=volume\n",
    "        labels = diagnos[di]\n",
    "#         return vol.unsqueeze(0), labels\n",
    "        return volume.unsqueeze(0), labels\n",
    "# 1: 21-79\n",
    "# 2: 30-80\n",
    "# 3: 15-55\n",
    "dataset=MyData3(data_type[choice],all_img)\n",
    "test_indices=[i for i in range(test_tot)]\n",
    "train_indices=[i for i in range(test_tot,test_tot+train_tot)]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "train_loader = DataLoader(dataset,sampler=train_sampler, num_workers=10, drop_last=False,batch_size=batch_size)\n",
    "test_loader = DataLoader(dataset,sampler=test_sampler, num_workers=10, drop_last=False,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
