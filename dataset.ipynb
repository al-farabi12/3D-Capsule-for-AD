{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current folder:/raid/anagashbayev/3D-Capsule-for-AD/\n",
      "Data folder:/raid/anagashbayev/\n",
      "SUBJECT_INDEPENDENT: True\n",
      "use_whole_data False\n",
      "use ALL copies of same subject False\n",
      "test/train imgs per subject 1/1\n",
      "\n",
      "\n",
      "Number of SUBJECTS in each group of dataset\t {'AD': 89, 'MCI': 212, 'CN': 161} in TOTAL  462\n",
      "Number of IMAGES in each group of dataset\t {'AD': 193, 'MCI': 909, 'CN': 442} in TOTAL  1544\n",
      "\n",
      "\n",
      "Number of USED SUBJECTS in each group\t\t {'AD': 89, 'MCI': 89, 'CN': 89} in TOTAL  267\n",
      "Number of USED IMAGES in each group \t\t {'AD': 89, 'MCI': 89, 'CN': 89} in TOTAL  267\n",
      "\n",
      "\n",
      "Number of SUBJECTS in each group of TEST split\t {'AD': 19, 'MCI': 19, 'CN': 19} in TOTAL  57\n",
      "Number of SUBJECTS in each group of TRAIN split\t {'AD': 70, 'MCI': 70, 'CN': 70} in TOTAL  210\n",
      "\n",
      "\n",
      "Number of IMAGES in each group of TEST split\t {'AD': 19, 'MCI': 19, 'CN': 19} in TOTAL  57\n",
      "Number of IMAGES in each group of TRAIN split\t {'AD': 70, 'MCI': 70, 'CN': 70} in TOTAL  210\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nb\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam,SGD\n",
    "from torchvision import datasets, transforms\n",
    "import datetime\n",
    "root = os.getcwd()+'/'\n",
    "print(f\"Current folder:{root}\")\n",
    "currentFolder = \"3D-Capsule-for-AD/\"\n",
    "data_path=root[:-len(currentFolder)]\n",
    "print(f\"Data folder:{data_path}\")\n",
    "data_15t_1mm = data_path+'15t/1mm-reg-nii-gz/'\n",
    "data_15t_2mm = data_path+'15t/2mm-reg-nii-gz/'\n",
    "data_3t_1mm = data_path+'3t/1mm-reg-nii-gz/'\n",
    "data_3t_2mm = data_path+'3t/2mm-reg-nii-gz/'\n",
    "data_type = [data_15t_1mm, data_15t_2mm, data_3t_1mm, data_3t_2mm]\n",
    "\n",
    "all_diagnos ={'AD': 0,'MCI': 1,'CN': 2}\n",
    "diagnos = {'AD': 0,'MCI': 1,'CN': 2}\n",
    "# val_dia = { 0:'AD', 1:'MCI',2:'CN'}\n",
    "# diagnos = {'AD': 0,'MCI': 1}\n",
    "# val_dia = { 0:'AD', 1:'MCI'}\n",
    "\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "SUBJECT_INDEPENDENT = True\n",
    "print(\"SUBJECT_INDEPENDENT:\",SUBJECT_INDEPENDENT)\n",
    "choice = 1 # 0==( 15t 1mm ) 1==(15t 2mm ) 2==( 3t 1mm ) 3==( 3t 2mm ) \n",
    "USE_CUDA = True\n",
    "# random_seed= 42\n",
    "# random.seed( random_seed )\n",
    "batch_size = 2#SHOULD BE devisable by 3\n",
    "use_whole_data  = False\n",
    "print(\"use_whole_data\",use_whole_data)\n",
    "split_portion = 0.2\n",
    "\n",
    "use_all_copies_of_same_subject = False\n",
    "print('use ALL copies of same subject',use_all_copies_of_same_subject)\n",
    "s = 1\n",
    "test_img_per_class_si = s\n",
    "train_img_per_class_si = s\n",
    "if not use_all_copies_of_same_subject:\n",
    "    print(f'test/train imgs per subject {test_img_per_class_si}/{train_img_per_class_si}')\n",
    "\n",
    "limit_testing_number = not use_whole_data\n",
    "test_sub_per_class = 19\n",
    "test_img_per_class_sd = 19\n",
    "limit_training_number = not use_whole_data\n",
    "train_sub_per_class = 70\n",
    "train_img_per_class_sd = 70\n",
    "\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# n_classes_by_val= len(set(diagnos.values()))\n",
    "# n_classes_by_key= len(set(diagnos.keys()))\n",
    "list_of_all_imgs = os.listdir(data_type[choice])\n",
    "total_imgs = {cls:[pat for pat in list_of_all_imgs if cls in pat] for cls in all_diagnos.keys()}\n",
    "n_imgs_total = {k:len(v) for k,v in total_imgs.items()}\n",
    "    \n",
    "by_diag = {}\n",
    "for i in diagnos:\n",
    "    by_diag[i]={}\n",
    "for file in list_of_all_imgs:\n",
    "    name, image, diagnose =file.split(\"__\")\n",
    "    if diagnose in diagnos:\n",
    "        if name not in by_diag[diagnose]:\n",
    "#             by_diag[diagnose][name]={}\n",
    "            by_diag[diagnose][name]=[]\n",
    "        by_diag[diagnose][name].append(file)\n",
    "            \n",
    "if SUBJECT_INDEPENDENT:\n",
    "    list_of_all_subs = set([i[:10] for i in list_of_all_imgs])\n",
    "\n",
    "    total_subs = {k:list(set([img[:10] for img in v])) for k,v in total_imgs.items()}\n",
    "    n_subj_total ={k:len(v) for k,v in total_subs.items()}\n",
    "    if limit_testing_number:\n",
    "        test_subs = {k:random.sample(v,test_sub_per_class) for k,v in total_subs.items()}\n",
    "    else:\n",
    "        validation_split = split_portion\n",
    "        test_subs = {k:random.sample(v,int(validation_split*len(v))) for k,v in total_subs.items()}\n",
    "    n_subs_test = {k:len(v) for k,v in test_subs.items()}\n",
    "    if use_all_copies_of_same_subject:\n",
    "        test_imgs = {k:[img for img in v if img[:10] in test_subs[k]] for k,v in total_imgs.items()}\n",
    "    else:\n",
    "        new_test_imgs = {}\n",
    "        for dia,group in test_subs.items():\n",
    "            new_group = []\n",
    "            for sub in group:\n",
    "                sample = random.sample(by_diag[dia][sub],min(test_img_per_class_si,len(by_diag[dia][sub])))\n",
    "                new_group+=sample\n",
    "            new_test_imgs[dia] = new_group\n",
    "        test_imgs = new_test_imgs\n",
    "    \n",
    "    n_imgs_test = {k:len(v) for k,v in test_imgs.items()}\n",
    "    train_subs = {}\n",
    "    for k in diagnos.keys():\n",
    "        train_subs[k]=[]\n",
    "    for k,v in total_subs.items():\n",
    "        for sub in v:\n",
    "            if sub not in test_subs[k]:\n",
    "                train_subs[k].append(sub)\n",
    "            if len(train_subs[k])==train_sub_per_class:\n",
    "                if limit_training_number:\n",
    "                    break\n",
    "\n",
    "    n_subs_train = {k:len(v) for k,v in train_subs.items()}\n",
    "    if use_all_copies_of_same_subject:\n",
    "        train_imgs = {k:[img for img in v if img[:10] in train_subs[k]] for k,v in total_imgs.items()}\n",
    "    else:\n",
    "        new_train_imgs = {}\n",
    "        for dia,group in train_subs.items():\n",
    "            new_group = []\n",
    "            for sub in group:\n",
    "                sample = random.sample(by_diag[dia][sub],min(train_img_per_class_si,len(by_diag[dia][sub])))\n",
    "                new_group+=sample\n",
    "            new_train_imgs[dia] = new_group\n",
    "        train_imgs = new_train_imgs\n",
    "    \n",
    "    n_imgs_train = {k:len(v) for k,v in train_imgs.items()}\n",
    "    n_imgs_used = {k:len(train_imgs[k])+ len(test_imgs[k]) for k in  diagnos.keys() }\n",
    "    n_subs_used = {k:len(train_subs[k])+ len(test_subs[k]) for k in  diagnos.keys() }\n",
    "    \n",
    "\n",
    "    print(\"\\n\")\n",
    "#     print(f\"Total Number of SUBJECTS of dataset {len(list_of_all_subs)}\")\n",
    "#     print(f\"Total Number of IMAGES of dataset {len(list_of_all_imgs)}\")\n",
    "    print(\"Number of SUBJECTS in each group of dataset\\t\", n_subj_total,\"in TOTAL \",len(list_of_all_subs))\n",
    "    print(\"Number of IMAGES in each group of dataset\\t\", n_imgs_total,\"in TOTAL \",len(list_of_all_imgs))\n",
    "    print(\"\\n\")\n",
    "#     print(f\"Total USED Number of SUBJECTS {sum(n_subs_used.values())}\")\n",
    "#     print(f\"Total USED Number of IMAGES {sum(n_imgs_used.values())}\")\n",
    "    print(\"Number of USED SUBJECTS in each group\\t\\t\", n_subs_used,\"in TOTAL \",sum(n_subs_used.values()))\n",
    "    print(\"Number of USED IMAGES in each group \\t\\t\", n_imgs_used,\"in TOTAL \",sum(n_imgs_used.values()))\n",
    "    print(\"\\n\")\n",
    "    print(\"Number of SUBJECTS in each group of TEST split\\t\",n_subs_test,\"in TOTAL \",sum(n_subs_test.values()))\n",
    "    print(\"Number of SUBJECTS in each group of TRAIN split\\t\", n_subs_train,\"in TOTAL \",sum(n_subs_train.values()))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of IMAGES in each group of TEST split\\t\",n_imgs_test,\"in TOTAL \",sum(n_imgs_test.values()))\n",
    "    print(\"Number of IMAGES in each group of TRAIN split\\t\", n_imgs_train,\"in TOTAL \",sum(n_imgs_train.values()))\n",
    "else:\n",
    "    test_imgs = {k:random.sample(v,test_sub_per_class) for k,v in total_imgs.items()}\n",
    "    if limit_testing_number:\n",
    "        test_imgs = {k:random.sample(v,test_img_per_class_sd) for k,v in total_imgs.items()}\n",
    "    else:\n",
    "        validation_split = split_portion\n",
    "        test_imgs = {k:random.sample(v,int(validation_split*len(v))) for k,v in total_imgs.items()}\n",
    "    n_imgs_test = {k:len(v) for k,v in test_imgs.items()}\n",
    "    rest_imgs = {k:[img for img in v if img not in test_imgs[k]] for k,v in total_imgs.items()}\n",
    "    if limit_training_number:\n",
    "        train_imgs = {k:random.sample(v,train_img_per_class_sd) for k,v in rest_imgs.items()}\n",
    "    else:\n",
    "        train_imgs = rest_imgs\n",
    "\n",
    "    n_imgs_train = {k:len(v) for k,v in train_imgs.items()}\n",
    "    n_imgs_used = {k:len(train_imgs[k])+ len(test_imgs[k]) for k in  diagnos.keys() }\n",
    "\n",
    "    print(\"\\n\")\n",
    "#     print(f\"Total Number of SUBJECTS of dataset {len(list_of_all_subs)}\")\n",
    "#     print(f\"Total Number of IMAGES of dataset {len(list_of_all_imgs)}\")\n",
    "#     print(\"Number of SUBJECTS in each group of dataset\\t\\t\\t\", n_subj_total)\n",
    "    print(\"Number of IMAGES in each group of dataset\\t\", n_imgs_total,\"in TOTAL \\t\",len(list_of_all_imgs))\n",
    "#     print(\"\\n\")\n",
    "#     print(f\"Total USED Number of SUBJECTS {sum(n_subs_used.values())}\")\n",
    "#     print(f\"Total USED Number of IMAGES {sum(n_imgs_used.values())}\")\n",
    "#     print(\"Number of USED SUBJECTS in each group\\t\\t\\t\", n_subs_used)\n",
    "    print(\"Number of USED IMAGES in each group\\t\\t\", n_imgs_used, \"in TOTAL \\t\",sum(n_imgs_used.values()))\n",
    "#     print(\"\\n\")\n",
    "#     print(\"Number of SUBJECTS in each group of TEST split\\t\",n_subs_test,\"in TOTAL \",sum(n_subs_test.values()))\n",
    "#     print(\"Number of SUBJECTS in each group of TRAIN split\\t\", n_subs_train,\"in TOTAL \",sum(n_subs_train.values()))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Number of IMAGES in each group of TEST split\\t\",n_imgs_test,\"in TOTAL \\t\",sum(n_imgs_test.values()))\n",
    "    print(\"Number of IMAGES in each group of TRAIN split\\t\", n_imgs_train,\"in TOTAL \\t\",sum(n_imgs_train.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img = []\n",
    "for i in test_imgs.values():\n",
    "    all_img = all_img+i\n",
    "for i in train_imgs.values():\n",
    "    all_img = all_img+i\n",
    "class MyDataFinal(Dataset):\n",
    "    def __init__(self, path,all_imgs):\n",
    "        self.folder=path\n",
    "        self.img = all_imgs\n",
    "        self.len = len(self.img)\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def __getitem__(self, index):\n",
    "#         temp_size=100\n",
    "#         vol = torch.zeros(temp_size,temp_size,temp_size,dtype=torch.float32)\n",
    "        add_noise = False #random.sample([True,False],1)[0]\n",
    "        di = self.img[index].split('__')[-1]\n",
    "        name =  os.path.join(self.folder,self.img[index])+'/mri/registered.nii.gz'\n",
    "        nii = nb.load(name)\n",
    "        volume = torch.from_numpy(nii.get_fdata()).type(torch.FloatTensor)#[7:82,10:100,10:75]\n",
    "#         x,y,z = volume.shape\n",
    "#         if add_noise:\n",
    "#             noise = 10*torch.randn(volume.shape)\n",
    "#             volume = volume + noise\n",
    "#         x,y,z= random.randint(0,temp_size-x),random.randint(0,temp_size-y),random.randint(0,temp_size-z)\n",
    "\n",
    "        volume = volume/volume.max()\n",
    "#         vol[x:x+75,y:y+90,z:z+65]=volume\n",
    "        labels = diagnos[di]\n",
    "#         return vol.unsqueeze(0), labels\n",
    "        return volume.unsqueeze(0), labels\n",
    "# 1: 21-79\n",
    "# 2: 30-80\n",
    "# 3: 15-55\n",
    "dataset=MyDataFinal(data_type[choice],all_img)\n",
    "test_tot=sum(n_imgs_test.values())\n",
    "train_tot=sum(n_imgs_train.values())\n",
    "if SUBJECT_INDEPENDENT:\n",
    "    test_indices=[i for i in range(test_tot)]\n",
    "    train_indices=[i for i in range(test_tot,test_tot+train_tot)]\n",
    "else:\n",
    "    test_indices=[i for i in range(test_tot)]\n",
    "    train_indices=[i for i in range(test_tot,test_tot+train_tot)]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "train_loader = DataLoader(dataset,sampler=train_sampler, num_workers=10, drop_last=False,batch_size=batch_size)\n",
    "test_loader = DataLoader(dataset,sampler=test_sampler, num_workers=10, drop_last=False,batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
